# Overview

| Developed by | Guardrails AI |
| --- | --- |
| Date of development | September 2, 2024 |
| Validator type | Format |
| Blog |  |
| License | Apache 2 |
| Input/Output | Output |

## Description

### Intended Use
This validator uses BespokeLabs.AI's minicheck API to evaluate LLM generated text against the provided context. It checks if the claims in the generated text are supported by the given context, using a configurable threshold for determining support. The validator can process the input as a whole or split it into individual sentences for more granular evaluation.

### Requirements
* Dependencies:
	- guardrails-ai>=0.4.0
	- nltk
	- bespokelabs
	- tenacity
* Foundation model access keys:
	- BESPOKE_API_KEY (get it from [BespokeLabs Console](https://console.bespokelabs.ai/))
## Installation

```bash
$ guardrails hub install hub://bespokelabs/bespoke_minicheck
```

## Usage Examples

### Validating string output via Python

In this example, we apply the validator to a string output generated by an LLM.

```python
# Import Guard and Validator
from guardrails.hub import BespokeMiniCheck
from guardrails import Guard

# Setup Guard
guard = Guard().use(
    BespokeMiniCheck,
    split_sentences=True,
    threshold=0.5,
    on_fail="fix"
)

guard.validate("Alex likes cats.", metadata={"context": "Alex likes cats and dogs"})  # Validator passes
guard.validate("Alex likes cats.", metadata={"context": "Alex likes dogs, but not cats."})  # Validator fails
```

# API Reference

**`__init__(self, threshold: float = 0.5, split_sentences: bool = True, on_fail: Optional[Callable] = None)`**
<ul>
Initializes a new instance of the BespokeMiniCheck class.

**Parameters**
- **`threshold`** *(float, optional)*: The minimum score for a claim to be considered supported. Defaults to 0.5.
- **`split_sentences`** *(bool, optional)*: Whether to split the input into sentences for individual evaluation. Defaults to True.
- **`on_fail`** *(Optional[Callable], optional)*: A callable to execute when the validation fails. Defaults to None.
</ul>
<br/>

**`validate(self, value: Any, metadata: Dict = {}) -> ValidationResult`**
<ul>
Validates the given `value` using the rules defined in this validator, relying on the `metadata` provided to customize the validation process. This method is automatically invoked by `guard.parse(...)`, ensuring the validation logic is applied to the input data.

Note:

1. This method should not be called directly by the user. Instead, invoke `guard.parse(...)` where this method will be called internally for each associated Validator.
2. When invoking `guard.parse(...)`, ensure to pass the appropriate `metadata` dictionary that includes keys and values required by this validator. If `guard` is associated with multiple validators, combine all necessary metadata into a single dictionary.

**Parameters**
- **`value`** *(Any)*: The input value to validate.
- **`metadata`** *(Dict)*: A dictionary containing metadata required for validation. Keys and values must match the expectations of this validator.

    | Key | Type | Description | Default |
    | --- | --- | --- | --- |
    | `threshold` | float | The minimum score for a claim to be considered supported. | Value set during initialization |
    | `split_sentences` | bool | Whether to split the input into sentences for individual evaluation. | Value set during initialization |
    | `contexts` | List[str] | A list of context strings to validate claims against. | [] |

**Returns**
- **`ValidationResult`**: A PassResult if all claims are supported, or a FailResult with an error message and a fix value containing only supported claims.

**Raises**
- **`ValueError`**: If the contexts provided are not a non-empty list of strings.
</ul>
